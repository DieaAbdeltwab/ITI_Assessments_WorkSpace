{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60f97978",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "201cee8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 15:27:54 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Spark Streaming\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1657baa-4075-44c3-9c33-c98f2ee48439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/diea/Documents/JN_WorkSpace/Spark/Spark/Day6/Lab-6\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efac8040",
   "metadata": {},
   "source": [
    "### Create the schema of the streamed files (check the column names and types from the CSV files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e273e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sample = spark.read.csv(\"./walmart/walmart_stock.csv\", header=True, inferSchema=True)\n",
    "df_sample.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4674d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = df_sample.schema\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f50fbeb",
   "metadata": {},
   "source": [
    "### Create the dataframe by reading the stream using format \"csv\" and the schema you created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d77671b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stream_df = spark.readStream.format(\"csv\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .schema(schema) \\\n",
    "    .load(\"./walmart\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e0e44",
   "metadata": {},
   "source": [
    "### Make sure the dataframe is streaming the files from the folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fc0fa13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "print(stream_df.isStreaming) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9d68de",
   "metadata": {},
   "source": [
    "### Create a stream writer into memory and specify the query name \"stock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdf7c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeStream_memory = stream_df.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"stock\") \\\n",
    "    .option(\"checkpointLocation\", \"./checkpoints/stock\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a5f9a4",
   "metadata": {},
   "source": [
    "### Start the write stream and make sure it works (read all columns from the table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d98c6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 15:28:12 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7aa4ccf5d340>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeStream_memory.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27bebb21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM stock\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769e6e1e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "16908fa6",
   "metadata": {},
   "source": [
    "### Remove the first row from the data (hint: drop the rows where ALL values are null), then add a new column \"diff\", which is the difference between high and low columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45219991",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = stream_df.na.drop(how=\"all\").withColumn(\"diff\", col(\"High\") - col(\"Low\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2eaa25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1f14581b",
   "metadata": {},
   "source": [
    "### Create a new write stream using the new generated dataframe and call the generate table \"modified_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1a96806",
   "metadata": {},
   "outputs": [],
   "source": [
    "writeStream_clean_memory = clean_df.writeStream \\\n",
    "    .format(\"memory\") \\\n",
    "    .queryName(\"modified_data\") \\\n",
    "    .option(\"checkpointLocation\", \"./checkpoints/modified_data\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb1be0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 15:28:24 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7aa496482450>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "writeStream_clean_memory.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969acbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|               diff|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996| 1.1900019999999998|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475| 0.8799969999999959|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|               1.25|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922| 0.5800020000000004|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|           0.630001|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109| 0.7299989999999994|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|0.48999799999999283|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 0.5999979999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996| 0.6000030000000081|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581| 0.5900010000000009|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131| 0.3799969999999959|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447| 0.9799999999999969|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 0.5800020000000004|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104| 0.4700020000000009|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|               1.25|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001| 0.5700000000000003|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436| 1.0700000000000003|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665| 0.5799979999999962|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994| 0.9700020000000009|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006| 0.9899979999999999|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM modified_data\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bcedd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453fbe76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e16c3036",
   "metadata": {},
   "source": [
    "### Write the generated data into files instead of the memory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e165a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 15:28:31 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "writeStream_clean_csv = clean_df.writeStream \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"path\", \"./walmart_write\")\\\n",
    "    .option(\"checkpointLocation\", \"./checkpoints/walmart_write/checkpoint\") \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441b76a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416b7c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72f07e3f",
   "metadata": {},
   "source": [
    "### Stop the query. Now, try reading the generated files into a normal dataframe\n",
    "- Create a schema and use it to read the data.\n",
    "- Show the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e06956f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/07/12 15:28:36 WARN DAGScheduler: Failed to cancel job group 1008aecf-15b9-48a8-81c7-4ff7b02ae3cb. Cannot find active jobs for it.\n",
      "25/07/12 15:28:36 WARN DAGScheduler: Failed to cancel job group 1008aecf-15b9-48a8-81c7-4ff7b02ae3cb. Cannot find active jobs for it.\n"
     ]
    }
   ],
   "source": [
    "writeStream_clean_csv.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c71ca2ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|               diff|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996| 1.1900019999999998|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475| 0.8799969999999959|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|               1.25|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922| 0.5800020000000004|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|           0.630001|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109| 0.7299989999999994|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|0.48999799999999283|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 0.5999979999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996| 0.6000030000000081|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581| 0.5900010000000009|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131| 0.3799969999999959|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447| 0.9799999999999969|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 0.5800020000000004|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104| 0.4700020000000009|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|               1.25|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001| 0.5700000000000003|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436| 1.0700000000000003|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665| 0.5799979999999962|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994| 0.9700020000000009|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006| 0.9899979999999999|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "final_schema = schema.add(\"diff\", DoubleType())\n",
    "\n",
    "final_df = spark.read.format(\"csv\") \\\n",
    "    .schema(final_schema) \\\n",
    "    .load(\"./walmart_write\")\n",
    "final_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4814d697",
   "metadata": {},
   "source": [
    "### Sort the dataframe based on the Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c51d91a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|               diff|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996| 1.1900019999999998|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475| 0.8799969999999959|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|               1.25|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922| 0.5800020000000004|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|           0.630001|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109| 0.7299989999999994|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|0.48999799999999283|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994| 0.5999979999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996| 0.6000030000000081|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581| 0.5900010000000009|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131| 0.3799969999999959|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447| 0.9799999999999969|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996| 0.5800020000000004|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104| 0.4700020000000009|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|               1.25|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001| 0.5700000000000003|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436| 1.0700000000000003|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665| 0.5799979999999962|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994| 0.9700020000000009|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006| 0.9899979999999999|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "final_df.orderBy(\"Date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e218d5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
